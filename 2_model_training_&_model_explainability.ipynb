{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ],
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# For seeing all columns\n",
    "pd.set_option('max_columns', None)\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "\n",
    "# For data-visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML model classes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "\n",
    "# For making pipelines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "# For model explainability\n",
    "#import eli5\n",
    "import shap\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# For cross-validation\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# For checking accuracy\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# For feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For replication of results\n",
    "np.random.seed(2021)\n",
    "\n",
    "# Check whether machine has GPU\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-12-03</td>\n",
       "      <td>221.341003</td>\n",
       "      <td>217.755005</td>\n",
       "      <td>219.839996</td>\n",
       "      <td>219.345001</td>\n",
       "      <td>10122532.0</td>\n",
       "      <td>65.268867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-12-04</td>\n",
       "      <td>221.240997</td>\n",
       "      <td>217.199005</td>\n",
       "      <td>219.557007</td>\n",
       "      <td>218.406006</td>\n",
       "      <td>8591649.0</td>\n",
       "      <td>64.989471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-12-05</td>\n",
       "      <td>226.350998</td>\n",
       "      <td>218.080994</td>\n",
       "      <td>218.518997</td>\n",
       "      <td>224.983002</td>\n",
       "      <td>12728929.0</td>\n",
       "      <td>66.946533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        High         Low        Open       Close      Volume  \\\n",
       "0  2007-12-03  221.341003  217.755005  219.839996  219.345001  10122532.0   \n",
       "1  2007-12-04  221.240997  217.199005  219.557007  218.406006   8591649.0   \n",
       "2  2007-12-05  226.350998  218.080994  218.518997  224.983002  12728929.0   \n",
       "\n",
       "   Adj Close  \n",
       "0  65.268867  \n",
       "1  64.989471  \n",
       "2  66.946533  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_dir = r\"C:\\Users\\smitr\\Desktop\\FinPython\\data\\nifty50\"\n",
    "file_name = \"SBIN.csv\"\n",
    "file_path_sbi = os.path.join(par_dir, file_name)\n",
    "\n",
    "par_dir_nifty = r\"C:\\Users\\smitr\\Desktop\\FinPython\\data\"\n",
    "file_name = \"NIFTY_17Sep07_09Nov20.csv\"\n",
    "file_path_niftySpot = os.path.join(par_dir_nifty, file_name)\n",
    "\n",
    "file_name = \"NiftyBank_17Sep07_06Nov20.csv\"\n",
    "file_path_bankNftySpot = os.path.join(par_dir_nifty, file_name)\n",
    "\n",
    "par_dir_int_indices = os.path.join(par_dir_nifty, \"International Indices\")\n",
    "file_path_nikkei = os.path.join(par_dir_int_indices, \"Nikkei225_04Jan80_08Jan21.csv\")\n",
    "\n",
    "#par_dir_int_indices = os.path.join(par_dir_nifty, \"International Indices\")\n",
    "#file_path_hngSng = os.path.join(par_dir_int_indices, \"HangSeng_31Dec86_08Jan21.csv\")\n",
    "\n",
    "df = pd.read_csv(file_path_sbi)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_transform(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_month_day(date):\n",
    "    return int(date.split(\"-\")[2])    \n",
    "\n",
    "def get_month(date):\n",
    "    return int(date.split(\"-\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>return</th>\n",
       "      <th>ret_pct</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-12-03</td>\n",
       "      <td>221.341003</td>\n",
       "      <td>217.755005</td>\n",
       "      <td>219.839996</td>\n",
       "      <td>219.345001</td>\n",
       "      <td>10122532.0</td>\n",
       "      <td>65.268867</td>\n",
       "      <td>0.494995</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-12-04</td>\n",
       "      <td>221.240997</td>\n",
       "      <td>217.199005</td>\n",
       "      <td>219.557007</td>\n",
       "      <td>218.406006</td>\n",
       "      <td>8591649.0</td>\n",
       "      <td>64.989471</td>\n",
       "      <td>1.151001</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-12-05</td>\n",
       "      <td>226.350998</td>\n",
       "      <td>218.080994</td>\n",
       "      <td>218.518997</td>\n",
       "      <td>224.983002</td>\n",
       "      <td>12728929.0</td>\n",
       "      <td>66.946533</td>\n",
       "      <td>-6.464005</td>\n",
       "      <td>-0.029581</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        High         Low        Open       Close      Volume  \\\n",
       "0  2007-12-03  221.341003  217.755005  219.839996  219.345001  10122532.0   \n",
       "1  2007-12-04  221.240997  217.199005  219.557007  218.406006   8591649.0   \n",
       "2  2007-12-05  226.350998  218.080994  218.518997  224.983002  12728929.0   \n",
       "\n",
       "   Adj Close    return   ret_pct  Target  \n",
       "0  65.268867  0.494995  0.002252       1  \n",
       "1  64.989471  1.151001  0.005242       1  \n",
       "2  66.946533 -6.464005 -0.029581       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"return\"] = df[\"Open\"] - df[\"Close\"]\n",
    "df[\"ret_pct\"] = (df[\"Open\"] - df[\"Close\"]) / df[\"Open\"]\n",
    "df[\"Target\"] = df[\"return\"].apply(target_transform)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>return</th>\n",
       "      <th>ret_pct</th>\n",
       "      <th>Target</th>\n",
       "      <th>Stock_gap</th>\n",
       "      <th>MonthDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>NiftySpot_gap</th>\n",
       "      <th>BankNiftySpot_gap</th>\n",
       "      <th>Nikkei_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-12-04</td>\n",
       "      <td>221.240997</td>\n",
       "      <td>217.199005</td>\n",
       "      <td>219.557007</td>\n",
       "      <td>218.406006</td>\n",
       "      <td>8591649.0</td>\n",
       "      <td>64.989471</td>\n",
       "      <td>1.151001</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>1</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5.200195</td>\n",
       "      <td>6.600586</td>\n",
       "      <td>-15.080078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-12-05</td>\n",
       "      <td>226.350998</td>\n",
       "      <td>218.080994</td>\n",
       "      <td>218.518997</td>\n",
       "      <td>224.983002</td>\n",
       "      <td>12728929.0</td>\n",
       "      <td>66.946533</td>\n",
       "      <td>-6.464005</td>\n",
       "      <td>-0.029581</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112991</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3.549805</td>\n",
       "      <td>6.350586</td>\n",
       "      <td>-61.240234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-12-06</td>\n",
       "      <td>229.917007</td>\n",
       "      <td>224.464005</td>\n",
       "      <td>226.445007</td>\n",
       "      <td>226.024994</td>\n",
       "      <td>10837323.0</td>\n",
       "      <td>67.256592</td>\n",
       "      <td>0.420013</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>1</td>\n",
       "      <td>1.462006</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1.049805</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>173.520508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-12-07</td>\n",
       "      <td>231.889008</td>\n",
       "      <td>225.501007</td>\n",
       "      <td>228.785004</td>\n",
       "      <td>229.822998</td>\n",
       "      <td>10566995.0</td>\n",
       "      <td>68.386726</td>\n",
       "      <td>-1.037994</td>\n",
       "      <td>-0.004537</td>\n",
       "      <td>0</td>\n",
       "      <td>2.760010</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8.899902</td>\n",
       "      <td>57.699219</td>\n",
       "      <td>118.160156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-12-10</td>\n",
       "      <td>231.960007</td>\n",
       "      <td>227.860001</td>\n",
       "      <td>229.841995</td>\n",
       "      <td>228.893005</td>\n",
       "      <td>5373405.0</td>\n",
       "      <td>68.110001</td>\n",
       "      <td>0.948990</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018997</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.299805</td>\n",
       "      <td>4.100586</td>\n",
       "      <td>50.959961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        High         Low        Open       Close      Volume  \\\n",
       "1  2007-12-04  221.240997  217.199005  219.557007  218.406006   8591649.0   \n",
       "2  2007-12-05  226.350998  218.080994  218.518997  224.983002  12728929.0   \n",
       "3  2007-12-06  229.917007  224.464005  226.445007  226.024994  10837323.0   \n",
       "4  2007-12-07  231.889008  225.501007  228.785004  229.822998  10566995.0   \n",
       "5  2007-12-10  231.960007  227.860001  229.841995  228.893005   5373405.0   \n",
       "\n",
       "   Adj Close    return   ret_pct  Target  Stock_gap  MonthDay  Month  \\\n",
       "1  64.989471  1.151001  0.005242       1   0.212006         4     12   \n",
       "2  66.946533 -6.464005 -0.029581       0   0.112991         5     12   \n",
       "3  67.256592  0.420013  0.001855       1   1.462006         6     12   \n",
       "4  68.386726 -1.037994 -0.004537       0   2.760010         7     12   \n",
       "5  68.110001  0.948990  0.004129       1   0.018997        10     12   \n",
       "\n",
       "   NiftySpot_gap  BankNiftySpot_gap  Nikkei_gap  \n",
       "1       5.200195           6.600586  -15.080078  \n",
       "2       3.549805           6.350586  -61.240234  \n",
       "3       1.049805          63.500000  173.520508  \n",
       "4       8.899902          57.699219  118.160156  \n",
       "5      -0.299805           4.100586   50.959961  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gap up/down of stock price gives a view about current sentiment regarding stock\n",
    "df[\"Stock_gap\"] = df[\"Open\"] - df[\"Close\"].shift(periods=1)\n",
    "#df[\"prev3_Target\"] = df[\"Target\"].shift(periods=3)\n",
    "\n",
    "# Using day of month as a feature\n",
    "df[\"MonthDay\"] = df[\"Date\"].apply(get_month_day)\n",
    "\n",
    "# Using month as a feature\n",
    "df[\"Month\"] = df[\"Date\"].apply(get_month)\n",
    "\n",
    "# Nifty spot gap up/down\n",
    "df_nfty_spot = pd.read_csv(file_path_niftySpot)\n",
    "df_nfty_spot[\"NiftySpot_gap\"] = df_nfty_spot[\"Open\"] - df_nfty_spot[\"Close\"].shift(periods=1)\n",
    "\n",
    "# Sector-wise gap up/down\n",
    "df_bankNfty_spot = pd.read_csv(file_path_bankNftySpot)\n",
    "df_bankNfty_spot[\"BankNiftySpot_gap\"] = df_bankNfty_spot[\"Open\"] - df_bankNfty_spot[\"Close\"].shift(periods=1)\n",
    "\n",
    "# Nikkei gap up/down\n",
    "df_nikkei = pd.read_csv(file_path_nikkei)\n",
    "df_nikkei[\"Nikkei_gap\"] = df_nikkei[\"Open\"] - df_nikkei[\"Close\"].shift(periods=1)\n",
    "\n",
    "# Hang Seng gap up/down\n",
    "#df_hngSng = pd.read_csv(file_path_hngSng)\n",
    "#df_hngSng[\"HangSeng_gap\"] = df_hngSng[\"Open\"] - df_hngSng[\"Close\"].shift(periods=1)\n",
    "\n",
    "# Merging data frames\n",
    "df = pd.merge(df, df_nfty_spot[[\"Date\", \"NiftySpot_gap\"]], on=\"Date\")\n",
    "df = pd.merge(df, df_bankNfty_spot[[\"Date\", \"BankNiftySpot_gap\"]], on=\"Date\")\n",
    "df = pd.merge(df, df_nikkei[[\"Date\", \"Nikkei_gap\"]], on=\"Date\")\n",
    "#df = pd.merge(df, df_hngSng[[\"Date\", \"HangSeng_gap\"]], on=\"Date\")\n",
    "\n",
    "# Dropping rows with NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>return</th>\n",
       "      <th>ret_pct</th>\n",
       "      <th>Target</th>\n",
       "      <th>Stock_gap</th>\n",
       "      <th>MonthDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>NiftySpot_gap</th>\n",
       "      <th>BankNiftySpot_gap</th>\n",
       "      <th>Nikkei_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-12-04</td>\n",
       "      <td>221.240997</td>\n",
       "      <td>217.199005</td>\n",
       "      <td>219.557007</td>\n",
       "      <td>218.406006</td>\n",
       "      <td>8591649.0</td>\n",
       "      <td>64.989471</td>\n",
       "      <td>1.151001</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>1</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5.200195</td>\n",
       "      <td>6.600586</td>\n",
       "      <td>-15.080078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-12-05</td>\n",
       "      <td>226.350998</td>\n",
       "      <td>218.080994</td>\n",
       "      <td>218.518997</td>\n",
       "      <td>224.983002</td>\n",
       "      <td>12728929.0</td>\n",
       "      <td>66.946533</td>\n",
       "      <td>-6.464005</td>\n",
       "      <td>-0.029581</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112991</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3.549805</td>\n",
       "      <td>6.350586</td>\n",
       "      <td>-61.240234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        High         Low        Open       Close      Volume  \\\n",
       "1  2007-12-04  221.240997  217.199005  219.557007  218.406006   8591649.0   \n",
       "2  2007-12-05  226.350998  218.080994  218.518997  224.983002  12728929.0   \n",
       "\n",
       "   Adj Close    return   ret_pct  Target  Stock_gap  MonthDay  Month  \\\n",
       "1  64.989471  1.151001  0.005242       1   0.212006         4     12   \n",
       "2  66.946533 -6.464005 -0.029581       0   0.112991         5     12   \n",
       "\n",
       "   NiftySpot_gap  BankNiftySpot_gap  Nikkei_gap  \n",
       "1       5.200195           6.600586  -15.080078  \n",
       "2       3.549805           6.350586  -61.240234  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(df)*0.8)\n",
    "print(train_size)\n",
    "\n",
    "train = df[:train_size]\n",
    "test = df.copy()[train_size:]\n",
    "\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>return</th>\n",
       "      <th>ret_pct</th>\n",
       "      <th>Target</th>\n",
       "      <th>Stock_gap</th>\n",
       "      <th>MonthDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>NiftySpot_gap</th>\n",
       "      <th>BankNiftySpot_gap</th>\n",
       "      <th>Nikkei_gap</th>\n",
       "      <th>MonthDay_enc</th>\n",
       "      <th>Month_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-12-04</td>\n",
       "      <td>221.240997</td>\n",
       "      <td>217.199005</td>\n",
       "      <td>219.557007</td>\n",
       "      <td>218.406006</td>\n",
       "      <td>8591649.0</td>\n",
       "      <td>64.989471</td>\n",
       "      <td>1.151001</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>1</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5.200195</td>\n",
       "      <td>6.600586</td>\n",
       "      <td>-15.080078</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.575419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-12-05</td>\n",
       "      <td>226.350998</td>\n",
       "      <td>218.080994</td>\n",
       "      <td>218.518997</td>\n",
       "      <td>224.983002</td>\n",
       "      <td>12728929.0</td>\n",
       "      <td>66.946533</td>\n",
       "      <td>-6.464005</td>\n",
       "      <td>-0.029581</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112991</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3.549805</td>\n",
       "      <td>6.350586</td>\n",
       "      <td>-61.240234</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.575419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-12-06</td>\n",
       "      <td>229.917007</td>\n",
       "      <td>224.464005</td>\n",
       "      <td>226.445007</td>\n",
       "      <td>226.024994</td>\n",
       "      <td>10837323.0</td>\n",
       "      <td>67.256592</td>\n",
       "      <td>0.420013</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>1</td>\n",
       "      <td>1.462006</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1.049805</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>173.520508</td>\n",
       "      <td>0.594203</td>\n",
       "      <td>0.575419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        High         Low        Open       Close      Volume  \\\n",
       "1  2007-12-04  221.240997  217.199005  219.557007  218.406006   8591649.0   \n",
       "2  2007-12-05  226.350998  218.080994  218.518997  224.983002  12728929.0   \n",
       "3  2007-12-06  229.917007  224.464005  226.445007  226.024994  10837323.0   \n",
       "\n",
       "   Adj Close    return   ret_pct  Target  Stock_gap  MonthDay  Month  \\\n",
       "1  64.989471  1.151001  0.005242       1   0.212006         4     12   \n",
       "2  66.946533 -6.464005 -0.029581       0   0.112991         5     12   \n",
       "3  67.256592  0.420013  0.001855       1   1.462006         6     12   \n",
       "\n",
       "   NiftySpot_gap  BankNiftySpot_gap  Nikkei_gap  MonthDay_enc  Month_enc  \n",
       "1       5.200195           6.600586  -15.080078      0.492958   0.575419  \n",
       "2       3.549805           6.350586  -61.240234      0.472222   0.575419  \n",
       "3       1.049805          63.500000  173.520508      0.594203   0.575419  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable = Key, Target prob = Value in dictionary\n",
    "mnthDay_encodings = train.groupby(['MonthDay'])['Target'].mean().to_dict() \n",
    "train['MonthDay_enc'] =  train['MonthDay'].map(mnthDay_encodings) \n",
    "test['MonthDay_enc'] =  test['MonthDay'].map(mnthDay_encodings) \n",
    "\n",
    "month_encodings = train.groupby(['Month'])['Target'].mean().to_dict() \n",
    "train['Month_enc'] =  train['Month'].map(month_encodings) \n",
    "test['Month_enc'] =  test['Month'].map(month_encodings) \n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.43333333333333335, 2: 0.5645161290322581, 3: 0.5, 4: 0.49295774647887325, 5: 0.4722222222222222, 6: 0.5942028985507246, 7: 0.5443037974683544, 8: 0.5466666666666666, 9: 0.527027027027027, 10: 0.5657894736842105, 11: 0.5492957746478874, 12: 0.6351351351351351, 13: 0.547945205479452, 14: 0.4722222222222222, 15: 0.4852941176470588, 16: 0.48717948717948717, 17: 0.589041095890411, 18: 0.5064935064935064, 19: 0.6578947368421053, 20: 0.5571428571428572, 21: 0.5, 22: 0.52, 23: 0.47540983606557374, 24: 0.5373134328358209, 25: 0.56, 26: 0.6231884057971014, 27: 0.5714285714285714, 28: 0.5526315789473685, 29: 0.5714285714285714, 30: 0.5074626865671642, 31: 0.5135135135135135}\n",
      "{1: 0.5792349726775956, 2: 0.582010582010582, 3: 0.5128205128205128, 4: 0.5371428571428571, 5: 0.5300546448087432, 6: 0.5141509433962265, 7: 0.4869109947643979, 8: 0.6054054054054054, 9: 0.4662576687116564, 10: 0.5515151515151515, 11: 0.5238095238095238, 12: 0.5754189944134078}\n"
     ]
    }
   ],
   "source": [
    "print(mnthDay_encodings)\n",
    "print(month_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2167, 6) (2167,)\n",
      "(542, 6) (542,)\n"
     ]
    }
   ],
   "source": [
    "not_feats = [\"Date\",\"High\",\"Low\",\"Open\",\"Close\",\"Volume\",\"Adj Close\",\n",
    "             \"return\",\"ret_pct\",\"Target\",\"MonthDay\",\"Month\"]\n",
    "feature_columns = list(set(train.columns.values) - set(not_feats))\n",
    "\n",
    "X_train, X_test = train[feature_columns], test[feature_columns]\n",
    "y_train, y_test = train.Target.values, test.Target.values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NiftySpot_gap</th>\n",
       "      <th>Month_enc</th>\n",
       "      <th>MonthDay_enc</th>\n",
       "      <th>Nikkei_gap</th>\n",
       "      <th>BankNiftySpot_gap</th>\n",
       "      <th>Stock_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.200195</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>-15.080078</td>\n",
       "      <td>6.600586</td>\n",
       "      <td>0.212006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.549805</td>\n",
       "      <td>0.575419</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>-61.240234</td>\n",
       "      <td>6.350586</td>\n",
       "      <td>0.112991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NiftySpot_gap  Month_enc  MonthDay_enc  Nikkei_gap  BankNiftySpot_gap  \\\n",
       "1       5.200195   0.575419      0.492958  -15.080078           6.600586   \n",
       "2       3.549805   0.575419      0.472222  -61.240234           6.350586   \n",
       "\n",
       "   Stock_gap  \n",
       "1   0.212006  \n",
       "2   0.112991  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions for checking model accuracy :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2021\n",
    "\n",
    "def get_highThresh_acc(y_pred_probs, y_test, thresh_prob=0.65):\n",
    "    \n",
    "    cnt, corr_predicts = 0, 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_pred_probs[i] > thresh_prob:    # Predict 1 (up move)\n",
    "            cnt += 1\n",
    "            if y_test[i] == 1:\n",
    "                corr_predicts += 1\n",
    "            else: pass\n",
    "        elif y_pred_probs[i] < 1.0 - thresh_prob:    # Predict 0 (down move)\n",
    "            cnt += 1\n",
    "            if y_test[i] == 0:\n",
    "                corr_predicts += 1\n",
    "            else: pass\n",
    "        else: continue\n",
    "            \n",
    "    print(\"Prediction accuracy : {}\".format(corr_predicts/cnt))\n",
    "    print(\"Percentage of datapoints predicted : {}\".format(cnt/len(y_test)))\n",
    "    print(\"No.of datapoints predicted : {}, Total datapoints : {}\".format(cnt, len(y_test)))\n",
    "\n",
    "    return\n",
    "\n",
    "def get_highThresh_acc_lr(y_pred_probs, y_test, thresh_prob=0.65):\n",
    "    \n",
    "    cnt, corr_predicts = 0, 0\n",
    "    for i in range(len(y_test)):\n",
    "        \n",
    "        if max(y_pred_probs[i]) > thresh_prob:\n",
    "            cnt += 1\n",
    "            if np.argmax(y_pred_probs[i]) == y_test[i]:\n",
    "                corr_predicts += 1\n",
    "                \n",
    "    print(\"Accuracy with {} threshold : {}\".format(thresh_prob, corr_predicts/cnt))\n",
    "    print(\"Percentage of datapoints predicted : {}\".format(cnt/len(y_test)))\n",
    "    print(\"No.of datapoints predicted : {}, Total datapoints : {}\".format(cnt, len(y_test)))\n",
    "\n",
    "    return      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying ML models on data :-\n",
    "<br>\n",
    "\n",
    "### i) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more of the test scores are non-finite: [       nan 0.55807092 0.55807092 0.55807092        nan        nan\n",
      "        nan        nan        nan 0.55621978 0.55621978        nan\n",
      " 0.55807092        nan        nan        nan 0.55807092 0.55807092\n",
      " 0.55576037        nan 0.55884252        nan 0.55575966        nan\n",
      "        nan        nan        nan 0.55575895 0.55575895 0.55575895\n",
      " 0.55621978        nan        nan        nan 0.55807092 0.55807092\n",
      "        nan        nan 0.55575895 0.55807092        nan 0.55575895\n",
      "        nan 0.55575895        nan        nan 0.55560463        nan\n",
      "        nan        nan        nan        nan        nan 0.55575895\n",
      "        nan        nan        nan 0.55575895        nan        nan\n",
      " 0.55575895 0.55621978        nan 0.55575895 0.55575895 0.55545102\n",
      " 0.55807092        nan 0.55575895 0.55575895        nan        nan\n",
      " 0.55807092 0.55807092        nan        nan 0.55714926        nan\n",
      " 0.55591327 0.55575966 0.55807092        nan        nan        nan\n",
      "        nan 0.55637481 0.55575895        nan        nan        nan\n",
      "        nan 0.55575895 0.55807092 0.55575895        nan 0.55621978\n",
      " 0.55807092        nan 0.55622049        nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.55884252147693\n",
      "Best Hyperparameters: {'solver': 'lbfgs', 'penalty': 'l2', 'C': 3036.6223939178935}\n"
     ]
    }
   ],
   "source": [
    "def loguniform(low=0, high=1, size=100):\n",
    "    return reciprocal(np.exp(low), np.exp(high)).rvs(size)\n",
    "\n",
    "# Create model\n",
    "lr = LogisticRegression(random_state=seed)\n",
    "\n",
    "# Define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=seed)\n",
    "\n",
    "# Define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs','liblinear']    \n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = loguniform(1e-5, 100)\n",
    "\n",
    "# Define search\n",
    "lr_search = RandomizedSearchCV(lr, space, n_iter=100, scoring='accuracy', \n",
    "                               n_jobs=-1, cv=cv, random_state=seed)\n",
    "\n",
    "# Execute search\n",
    "lr_result = lr_search.fit(X_train, y_train)\n",
    "\n",
    "# Summarize result\n",
    "print('Best Score: {}'.format(lr_result.best_score_))\n",
    "print('Best Hyperparameters: {}'.format(lr_result.best_params_))\n",
    "\n",
    "#y_pred_probabs = lr.predict_proba(X_test)\n",
    "#get_highThresh_acc_lr(y_pred_probabs, y_test, 0.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 3036.6223939178935,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 2021,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting best hyperparameters \n",
    "lr.set_params(**lr_result.best_params_)\n",
    "lr.get_params(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy : 0.518450184501845\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model after initializing with best hyperparameters\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Applying model on test set\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"Test accuracy : {}\".format(accuracy_score(y_true=y_test,y_pred=y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.61130674e-03,  2.03136566e+00,  4.59746036e+00,\n",
       "         7.45858135e-04, -6.88412048e-04,  9.50372531e-02]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.941\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        MonthDay_enc\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.91%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.299\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Month_enc\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 97.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.095\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Stock_gap\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.92%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.001\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Nikkei_gap\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.92%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.001\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        BankNiftySpot_gap\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.81%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        NiftySpot_gap\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.54%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.599\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(lr, feature_names = train[feature_columns].columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Month day encodings & month encoding features are most important. Thus, it is pretty clear that the model isnt making a clever prediction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) K-Nearest Neighbours :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :- 0.5239852398523985\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "# Fit the model to data\n",
    "neigh.fit(X_train, y_train)\n",
    "print(\"Accuracy :- {}\".format(neigh.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Random Forest :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-24f43940044a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prepare the cross-validation procedure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create Random Forest model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m rfc = RandomForestClassifier(n_estimators=10,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KFold' is not defined"
     ]
    }
   ],
   "source": [
    "# Prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "\n",
    "# Create Random Forest model\n",
    "rfc = RandomForestClassifier(n_estimators=10,\n",
    "                              random_state=seed)\n",
    "# Evaluate model\n",
    "scores = cross_val_score(rfc, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# Report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n",
    "\n",
    "#rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "# Need to load JS viz in notebook\n",
    "shap.initjs()\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "rf_explainer = shap.TreeExplainer(rfc)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "shap.force_plot(shap_values[1], X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv) SVMs :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5350553505535055"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nu_svm_params = {\"nu\":0.1,\n",
    "                 \"random_state\":2021}\n",
    "\n",
    "skl = StandardScaler()\n",
    "X_train = skl.fit_transform(X_train)\n",
    "\n",
    "nu_svm_clf =  NuSVC(**nu_svm_params)\n",
    "nu_svm_clf.fit(X_train, y_train)\n",
    "\n",
    "X_test = skl.transform(X_test)\n",
    "nu_svm_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5350553505535055"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_svm = SVC(random_state=2021,\n",
    "             kernel=\"rbf\")\n",
    "rbf_svm.fit(X_train, y_train)\n",
    "\n",
    "X_test = skl.transform(X_test)\n",
    "rbf_svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv) XGBoost :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.5 threshold :- 0.5630144566645916\n",
      "Accuracy with 0.9 threshold : 0.6666666666666666\n",
      "Percentage of datapoints predicted : 0.033210332103321034\n",
      "No.of datapoints predicted : 18, Total datapoints : 542\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Specify XGBoost parameters\n",
    "params = {\n",
    "    'max_depth': 6,  # the maximum depth of each tree\n",
    "    'eta': 0.2,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 2}  # the number of classes that exist in this datset\n",
    "\n",
    "# No.of training iterations\n",
    "num_iters = 50  \n",
    "\n",
    "# Create & Fit model\n",
    "xg_boost = xgb.train(params, dtrain, num_iters)\n",
    "\n",
    "# Predict classes for test set\n",
    "preds = xg_boost.predict(dtest)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "# Print test accuracy\n",
    "print(\"Accuracy with 0.5 threshold :- {}\".format(precision_score(y_test, best_preds, average='macro')))\n",
    "get_highThresh_acc_lr(preds, y_test, thresh_prob=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot feature importance\n",
    "plot_importance(xg_boost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation :-** From the above plot its clear that the **opening gaps for a day get the most importance**. This shows that a a day's movement is more dependent on that day's opening sentiment rather than historic monthly or date wise sentiments. Now this is a bit **clever**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.95%\n"
     ]
    }
   ],
   "source": [
    "#import XGBoost classifier and accuracy\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "params = {'learning_rate':0.03, \n",
    "          'n_estimators':810,    # Number of iterations of boosting\n",
    "          'max_depth':6,     # Max depth of each tree\n",
    "          'verbosity':0,     # Silent, i.e, print no messages while training\n",
    "          'n_jobs':-1}       # Use all CPU cores\n",
    "\n",
    "#instantiate model and train\n",
    "xgb_clf = XGBClassifier(**params)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test set\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot feature importance\n",
    "plot_importance(xgb_clf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v) Neural Network :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fcnn = Sequential()\n",
    "fcnn.add(Dense(4, input_dim=6, activation=\"relu\"))\n",
    "fcnn.add(Dense(2, activation=\"relu\"))\n",
    "fcnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "fcnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1841 samples, validate on 326 samples\n",
      "Epoch 1/30\n",
      "1841/1841 [==============================] - ETA: 5:06 - loss: 0.7365 - acc: 0.562 - ETA: 36s - loss: 0.7684 - acc: 0.500 - ETA: 11s - loss: 0.7819 - acc: 0.47 - ETA: 5s - loss: 0.7714 - acc: 0.4703 - ETA: 2s - loss: 0.7533 - acc: 0.485 - ETA: 1s - loss: 0.7511 - acc: 0.474 - ETA: 0s - loss: 0.7524 - acc: 0.468 - ETA: 0s - loss: 0.7462 - acc: 0.470 - 3s 2ms/step - loss: 0.7448 - acc: 0.4699 - val_loss: 0.7371 - val_acc: 0.4325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.7171 - acc: 0.375 - ETA: 0s - loss: 0.7187 - acc: 0.486 - ETA: 0s - loss: 0.7295 - acc: 0.475 - ETA: 0s - loss: 0.7276 - acc: 0.476 - ETA: 0s - loss: 0.7246 - acc: 0.475 - ETA: 0s - loss: 0.7204 - acc: 0.481 - ETA: 0s - loss: 0.7186 - acc: 0.480 - 0s 210us/step - loss: 0.7161 - acc: 0.4840 - val_loss: 0.7136 - val_acc: 0.4540\n",
      "Epoch 3/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.7244 - acc: 0.312 - ETA: 0s - loss: 0.7070 - acc: 0.545 - ETA: 0s - loss: 0.7150 - acc: 0.510 - ETA: 0s - loss: 0.7105 - acc: 0.494 - ETA: 0s - loss: 0.7069 - acc: 0.492 - ETA: 0s - loss: 0.7073 - acc: 0.488 - ETA: 0s - loss: 0.7075 - acc: 0.485 - ETA: 0s - loss: 0.7062 - acc: 0.489 - 0s 216us/step - loss: 0.7059 - acc: 0.4916 - val_loss: 0.7023 - val_acc: 0.4908\n",
      "Epoch 4/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6941 - acc: 0.437 - ETA: 0s - loss: 0.6980 - acc: 0.525 - ETA: 0s - loss: 0.7096 - acc: 0.492 - ETA: 0s - loss: 0.7052 - acc: 0.486 - ETA: 0s - loss: 0.7034 - acc: 0.496 - ETA: 0s - loss: 0.7016 - acc: 0.502 - ETA: 0s - loss: 0.7013 - acc: 0.501 - ETA: 0s - loss: 0.7009 - acc: 0.502 - 0s 212us/step - loss: 0.7009 - acc: 0.5024 - val_loss: 0.6957 - val_acc: 0.5123\n",
      "Epoch 5/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.7142 - acc: 0.312 - ETA: 0s - loss: 0.6992 - acc: 0.503 - ETA: 0s - loss: 0.6979 - acc: 0.505 - ETA: 0s - loss: 0.6987 - acc: 0.503 - ETA: 0s - loss: 0.6979 - acc: 0.499 - ETA: 0s - loss: 0.7004 - acc: 0.496 - ETA: 0s - loss: 0.7002 - acc: 0.494 - 0s 208us/step - loss: 0.6982 - acc: 0.5046 - val_loss: 0.6921 - val_acc: 0.5307\n",
      "Epoch 6/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.7496 - acc: 0.625 - ETA: 0s - loss: 0.7068 - acc: 0.550 - ETA: 0s - loss: 0.7010 - acc: 0.535 - ETA: 0s - loss: 0.7014 - acc: 0.510 - ETA: 0s - loss: 0.6989 - acc: 0.516 - ETA: 0s - loss: 0.6983 - acc: 0.513 - ETA: 0s - loss: 0.6981 - acc: 0.508 - ETA: 0s - loss: 0.6972 - acc: 0.510 - 0s 217us/step - loss: 0.6966 - acc: 0.5133 - val_loss: 0.6903 - val_acc: 0.5399\n",
      "Epoch 7/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.7129 - acc: 0.375 - ETA: 0s - loss: 0.7013 - acc: 0.495 - ETA: 0s - loss: 0.6950 - acc: 0.526 - ETA: 0s - loss: 0.6949 - acc: 0.517 - ETA: 0s - loss: 0.6949 - acc: 0.516 - ETA: 0s - loss: 0.6936 - acc: 0.521 - ETA: 0s - loss: 0.6952 - acc: 0.519 - ETA: 0s - loss: 0.6952 - acc: 0.517 - 0s 215us/step - loss: 0.6952 - acc: 0.5166 - val_loss: 0.6888 - val_acc: 0.5368\n",
      "Epoch 8/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.7163 - acc: 0.437 - ETA: 0s - loss: 0.6962 - acc: 0.504 - ETA: 0s - loss: 0.6926 - acc: 0.533 - ETA: 0s - loss: 0.6930 - acc: 0.528 - ETA: 0s - loss: 0.6939 - acc: 0.522 - ETA: 0s - loss: 0.6932 - acc: 0.525 - ETA: 0s - loss: 0.6943 - acc: 0.521 - ETA: 0s - loss: 0.6938 - acc: 0.523 - 0s 217us/step - loss: 0.6941 - acc: 0.5215 - val_loss: 0.6880 - val_acc: 0.5368\n",
      "Epoch 9/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6833 - acc: 0.562 - ETA: 0s - loss: 0.6846 - acc: 0.566 - ETA: 0s - loss: 0.6898 - acc: 0.541 - ETA: 0s - loss: 0.6901 - acc: 0.531 - ETA: 0s - loss: 0.6890 - acc: 0.539 - ETA: 0s - loss: 0.6914 - acc: 0.526 - ETA: 0s - loss: 0.6928 - acc: 0.523 - 0s 204us/step - loss: 0.6932 - acc: 0.5220 - val_loss: 0.6868 - val_acc: 0.5583\n",
      "Epoch 10/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6799 - acc: 0.625 - ETA: 0s - loss: 0.6869 - acc: 0.555 - ETA: 0s - loss: 0.6894 - acc: 0.536 - ETA: 0s - loss: 0.6900 - acc: 0.540 - ETA: 0s - loss: 0.6900 - acc: 0.544 - ETA: 0s - loss: 0.6910 - acc: 0.538 - ETA: 0s - loss: 0.6912 - acc: 0.533 - ETA: 0s - loss: 0.6921 - acc: 0.530 - 0s 218us/step - loss: 0.6924 - acc: 0.5296 - val_loss: 0.6861 - val_acc: 0.5644\n",
      "Epoch 11/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6271 - acc: 0.937 - ETA: 0s - loss: 0.6825 - acc: 0.580 - ETA: 0s - loss: 0.6891 - acc: 0.541 - ETA: 0s - loss: 0.6917 - acc: 0.525 - ETA: 0s - loss: 0.6893 - acc: 0.544 - ETA: 0s - loss: 0.6899 - acc: 0.543 - ETA: 0s - loss: 0.6906 - acc: 0.535 - 0s 202us/step - loss: 0.6918 - acc: 0.5285 - val_loss: 0.6852 - val_acc: 0.5675\n",
      "Epoch 12/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6954 - acc: 0.562 - ETA: 0s - loss: 0.6783 - acc: 0.604 - ETA: 0s - loss: 0.6855 - acc: 0.562 - ETA: 0s - loss: 0.6865 - acc: 0.559 - ETA: 0s - loss: 0.6893 - acc: 0.541 - ETA: 0s - loss: 0.6896 - acc: 0.540 - ETA: 0s - loss: 0.6898 - acc: 0.537 - ETA: 0s - loss: 0.6908 - acc: 0.534 - ETA: 0s - loss: 0.6916 - acc: 0.530 - ETA: 0s - loss: 0.6914 - acc: 0.530 - 1s 283us/step - loss: 0.6913 - acc: 0.5312 - val_loss: 0.6848 - val_acc: 0.5675\n",
      "Epoch 13/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6934 - acc: 0.562 - ETA: 0s - loss: 0.6930 - acc: 0.519 - ETA: 0s - loss: 0.6959 - acc: 0.506 - ETA: 0s - loss: 0.6923 - acc: 0.525 - ETA: 0s - loss: 0.6925 - acc: 0.525 - ETA: 0s - loss: 0.6928 - acc: 0.523 - ETA: 0s - loss: 0.6900 - acc: 0.537 - ETA: 0s - loss: 0.6909 - acc: 0.532 - 0s 217us/step - loss: 0.6910 - acc: 0.5318 - val_loss: 0.6846 - val_acc: 0.5706\n",
      "Epoch 14/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.7030 - acc: 0.500 - ETA: 0s - loss: 0.6987 - acc: 0.496 - ETA: 0s - loss: 0.6907 - acc: 0.536 - ETA: 0s - loss: 0.6913 - acc: 0.532 - ETA: 0s - loss: 0.6918 - acc: 0.528 - ETA: 0s - loss: 0.6913 - acc: 0.531 - ETA: 0s - loss: 0.6914 - acc: 0.530 - 0s 203us/step - loss: 0.6906 - acc: 0.5361 - val_loss: 0.6848 - val_acc: 0.5706\n",
      "Epoch 15/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.7092 - acc: 0.375 - ETA: 0s - loss: 0.6881 - acc: 0.544 - ETA: 0s - loss: 0.6865 - acc: 0.553 - ETA: 0s - loss: 0.6900 - acc: 0.536 - ETA: 0s - loss: 0.6899 - acc: 0.540 - ETA: 0s - loss: 0.6897 - acc: 0.541 - ETA: 0s - loss: 0.6909 - acc: 0.534 - ETA: 0s - loss: 0.6902 - acc: 0.536 - 0s 220us/step - loss: 0.6902 - acc: 0.5367 - val_loss: 0.6843 - val_acc: 0.5767\n",
      "Epoch 16/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.7069 - acc: 0.437 - ETA: 0s - loss: 0.6943 - acc: 0.527 - ETA: 0s - loss: 0.6907 - acc: 0.542 - ETA: 0s - loss: 0.6938 - acc: 0.519 - ETA: 0s - loss: 0.6926 - acc: 0.526 - ETA: 0s - loss: 0.6913 - acc: 0.528 - ETA: 0s - loss: 0.6911 - acc: 0.528 - 0s 205us/step - loss: 0.6899 - acc: 0.5372 - val_loss: 0.6842 - val_acc: 0.5767\n",
      "Epoch 17/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.7233 - acc: 0.500 - ETA: 0s - loss: 0.6915 - acc: 0.515 - ETA: 0s - loss: 0.6891 - acc: 0.545 - ETA: 0s - loss: 0.6883 - acc: 0.554 - ETA: 0s - loss: 0.6881 - acc: 0.550 - ETA: 0s - loss: 0.6887 - acc: 0.545 - ETA: 0s - loss: 0.6885 - acc: 0.547 - ETA: 0s - loss: 0.6883 - acc: 0.548 - ETA: 0s - loss: 0.6886 - acc: 0.546 - ETA: 0s - loss: 0.6892 - acc: 0.543 - 1s 282us/step - loss: 0.6896 - acc: 0.5416 - val_loss: 0.6839 - val_acc: 0.5798\n",
      "Epoch 18/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6606 - acc: 0.687 - ETA: 0s - loss: 0.6861 - acc: 0.547 - ETA: 0s - loss: 0.6883 - acc: 0.546 - ETA: 0s - loss: 0.6893 - acc: 0.539 - ETA: 0s - loss: 0.6889 - acc: 0.544 - ETA: 0s - loss: 0.6903 - acc: 0.539 - ETA: 0s - loss: 0.6895 - acc: 0.542 - ETA: 0s - loss: 0.6891 - acc: 0.543 - 0s 220us/step - loss: 0.6894 - acc: 0.5421 - val_loss: 0.6838 - val_acc: 0.5798\n",
      "Epoch 19/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6743 - acc: 0.625 - ETA: 0s - loss: 0.6938 - acc: 0.515 - ETA: 0s - loss: 0.6942 - acc: 0.509 - ETA: 0s - loss: 0.6888 - acc: 0.539 - ETA: 0s - loss: 0.6895 - acc: 0.541 - ETA: 0s - loss: 0.6878 - acc: 0.553 - ETA: 0s - loss: 0.6891 - acc: 0.547 - 0s 200us/step - loss: 0.6892 - acc: 0.5470 - val_loss: 0.6839 - val_acc: 0.5706\n",
      "Epoch 20/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.7232 - acc: 0.375 - ETA: 0s - loss: 0.6892 - acc: 0.513 - ETA: 0s - loss: 0.6883 - acc: 0.540 - ETA: 0s - loss: 0.6899 - acc: 0.531 - ETA: 0s - loss: 0.6890 - acc: 0.539 - ETA: 0s - loss: 0.6875 - acc: 0.549 - ETA: 0s - loss: 0.6877 - acc: 0.547 - ETA: 0s - loss: 0.6885 - acc: 0.544 - 0s 231us/step - loss: 0.6887 - acc: 0.5454 - val_loss: 0.6840 - val_acc: 0.5767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6992 - acc: 0.437 - ETA: 0s - loss: 0.6798 - acc: 0.595 - ETA: 0s - loss: 0.6884 - acc: 0.553 - ETA: 0s - loss: 0.6893 - acc: 0.552 - ETA: 0s - loss: 0.6892 - acc: 0.546 - ETA: 0s - loss: 0.6884 - acc: 0.551 - ETA: 0s - loss: 0.6891 - acc: 0.545 - 0s 197us/step - loss: 0.6885 - acc: 0.5475 - val_loss: 0.6837 - val_acc: 0.5859\n",
      "Epoch 22/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6720 - acc: 0.625 - ETA: 0s - loss: 0.6861 - acc: 0.562 - ETA: 0s - loss: 0.6900 - acc: 0.537 - ETA: 0s - loss: 0.6898 - acc: 0.544 - ETA: 0s - loss: 0.6879 - acc: 0.551 - ETA: 0s - loss: 0.6885 - acc: 0.547 - ETA: 0s - loss: 0.6889 - acc: 0.544 - 0s 197us/step - loss: 0.6882 - acc: 0.5464 - val_loss: 0.6834 - val_acc: 0.5828\n",
      "Epoch 23/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6410 - acc: 0.875 - ETA: 0s - loss: 0.6888 - acc: 0.546 - ETA: 0s - loss: 0.6854 - acc: 0.560 - ETA: 0s - loss: 0.6872 - acc: 0.549 - ETA: 0s - loss: 0.6869 - acc: 0.549 - ETA: 0s - loss: 0.6879 - acc: 0.549 - ETA: 0s - loss: 0.6876 - acc: 0.550 - ETA: 0s - loss: 0.6880 - acc: 0.547 - 0s 219us/step - loss: 0.6877 - acc: 0.5464 - val_loss: 0.6832 - val_acc: 0.5736\n",
      "Epoch 24/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6570 - acc: 0.687 - ETA: 0s - loss: 0.6822 - acc: 0.598 - ETA: 0s - loss: 0.6843 - acc: 0.567 - ETA: 0s - loss: 0.6886 - acc: 0.541 - ETA: 0s - loss: 0.6882 - acc: 0.542 - ETA: 0s - loss: 0.6882 - acc: 0.538 - ETA: 0s - loss: 0.6878 - acc: 0.547 - 0s 185us/step - loss: 0.6875 - acc: 0.5486 - val_loss: 0.6830 - val_acc: 0.5675\n",
      "Epoch 25/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6742 - acc: 0.687 - ETA: 0s - loss: 0.6831 - acc: 0.572 - ETA: 0s - loss: 0.6880 - acc: 0.550 - ETA: 0s - loss: 0.6864 - acc: 0.561 - ETA: 0s - loss: 0.6877 - acc: 0.553 - ETA: 0s - loss: 0.6888 - acc: 0.550 - ETA: 0s - loss: 0.6875 - acc: 0.553 - 0s 192us/step - loss: 0.6872 - acc: 0.5551 - val_loss: 0.6824 - val_acc: 0.5767\n",
      "Epoch 26/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6866 - acc: 0.437 - ETA: 0s - loss: 0.6818 - acc: 0.559 - ETA: 0s - loss: 0.6888 - acc: 0.533 - ETA: 0s - loss: 0.6861 - acc: 0.550 - ETA: 0s - loss: 0.6833 - acc: 0.561 - ETA: 0s - loss: 0.6858 - acc: 0.552 - ETA: 0s - loss: 0.6869 - acc: 0.555 - ETA: 0s - loss: 0.6869 - acc: 0.555 - 0s 230us/step - loss: 0.6869 - acc: 0.5562 - val_loss: 0.6822 - val_acc: 0.5859\n",
      "Epoch 27/30\n",
      "1841/1841 [==============================] - ETA: 1s - loss: 0.7367 - acc: 0.312 - ETA: 0s - loss: 0.6960 - acc: 0.515 - ETA: 0s - loss: 0.6862 - acc: 0.557 - ETA: 0s - loss: 0.6832 - acc: 0.577 - ETA: 0s - loss: 0.6872 - acc: 0.554 - ETA: 0s - loss: 0.6878 - acc: 0.553 - ETA: 0s - loss: 0.6870 - acc: 0.560 - ETA: 0s - loss: 0.6873 - acc: 0.555 - ETA: 0s - loss: 0.6852 - acc: 0.567 - 1s 274us/step - loss: 0.6863 - acc: 0.5627 - val_loss: 0.6817 - val_acc: 0.5798\n",
      "Epoch 28/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.500 - ETA: 0s - loss: 0.6834 - acc: 0.547 - ETA: 0s - loss: 0.6821 - acc: 0.575 - ETA: 0s - loss: 0.6829 - acc: 0.577 - ETA: 0s - loss: 0.6846 - acc: 0.570 - ETA: 0s - loss: 0.6833 - acc: 0.573 - ETA: 0s - loss: 0.6838 - acc: 0.571 - ETA: 0s - loss: 0.6847 - acc: 0.570 - 0s 235us/step - loss: 0.6859 - acc: 0.5622 - val_loss: 0.6817 - val_acc: 0.5828\n",
      "Epoch 29/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.6804 - acc: 0.625 - ETA: 0s - loss: 0.6783 - acc: 0.579 - ETA: 0s - loss: 0.6842 - acc: 0.564 - ETA: 0s - loss: 0.6830 - acc: 0.572 - ETA: 0s - loss: 0.6837 - acc: 0.568 - ETA: 0s - loss: 0.6849 - acc: 0.563 - ETA: 0s - loss: 0.6846 - acc: 0.568 - 0s 194us/step - loss: 0.6857 - acc: 0.5649 - val_loss: 0.6820 - val_acc: 0.5828\n",
      "Epoch 30/30\n",
      "1841/1841 [==============================] - ETA: 0s - loss: 0.7079 - acc: 0.437 - ETA: 0s - loss: 0.6930 - acc: 0.513 - ETA: 0s - loss: 0.6885 - acc: 0.535 - ETA: 0s - loss: 0.6847 - acc: 0.557 - ETA: 0s - loss: 0.6863 - acc: 0.559 - ETA: 0s - loss: 0.6855 - acc: 0.562 - ETA: 0s - loss: 0.6853 - acc: 0.564 - 0s 193us/step - loss: 0.6855 - acc: 0.5660 - val_loss: 0.6822 - val_acc: 0.5767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1631c489c18>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the model\n",
    "fcnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Defining callbacks\n",
    "filepath=\"SBIN_move_predictor_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Scaling the data for better model fit\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Fitting the model\n",
    "fcnn.fit(X_train, y_train, epochs=30, \n",
    "         batch_size=16, validation_split=0.15,\n",
    "         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy : 51.845018450184504\n"
     ]
    }
   ],
   "source": [
    "def get_test_acc(y_pred, y_test):\n",
    "    \n",
    "    correct = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == y_test[i]: correct += 1\n",
    "        else: pass\n",
    "        \n",
    "    return 100*correct/len(y_pred)\n",
    "\n",
    "\n",
    "# Scaling test data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Applying model on test data\n",
    "y_pred = fcnn.predict_classes(X_test)\n",
    "y_pred = np.squeeze(y_pred)\n",
    "\n",
    "print(\"Test set accuracy : {}\".format(get_test_acc(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ensembles :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.540590405904059"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Creating Voting classifier\n",
    "vote_clf = VotingClassifier(estimators=[('lr', lr),\n",
    "                                     ('knn', neigh),\n",
    "                                     ('xgb', xgb_clf)],\n",
    "                         voting='hard')\n",
    "\n",
    "# Fitting voting classifer model\n",
    "vote_clf.fit(X_train,y_train)\n",
    "\n",
    "# Applying on test set\n",
    "vote_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(classifiers=[LogisticRegression(C=3036.6223939178935,\n",
       "                                                   random_state=2021),\n",
       "                                KNeighborsClassifier(),\n",
       "                                XGBClassifier(learning_rate=0.03, max_depth=6,\n",
       "                                              n_estimators=810, n_jobs=-1,\n",
       "                                              verbosity=0)],\n",
       "                   fit_base_estimators=False,\n",
       "                   meta_classifier=LogisticRegression(random_state=2021),\n",
       "                   use_clones=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "meta_lr = LogisticRegression(random_state=2021)\n",
    "\n",
    "sclf = StackingClassifier(classifiers=[lr, neigh, xgb_clf], \n",
    "                          meta_classifier=meta_lr,\n",
    "                          fit_base_estimators=False)\n",
    "\n",
    "sclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5295202952029521"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test == sclf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
